{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3JDvj94xX4Fwl1kO/R5GA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PACxLXHnmviJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adversarial-robustness-toolbox\n",
        "!pip install tensorflow-privacy\n",
        "!pip install --upgrade tensorflow-estimator==2.3.0\n",
        "!pip install --upgrade tensorflow==2.14.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bqPCkZuJm0R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('preprocessado_iot-23-2.csv', on_bad_lines='skip')\n",
        "df.drop(['uid', 'service', 'duration','resp_bytes', 'orig_bytes', 'conn_state', 'local_orig',\n",
        "         'local_resp', 'missed_bytes', 'history', 'orig_pkts', 'resp_pkts', 'resp_ip_bytes'],\n",
        "         axis=1, inplace=True, errors='ignore')\n",
        "df.rename(columns={'tunnel_parents   label   detailed-label': 'label'}, inplace=True)\n",
        "df['label'] = df['label'].str.split().str[-1]\n",
        "df = df[~df['label'].isin(['Attack','C&C-HeartBeat','C&C-Torii','C&C-FileDownload','FileDownload',\n",
        "                           'C&C-HeartBeat-FileDownload','C&C-Mirai'])]"
      ],
      "metadata": {
        "id": "nzZhqIgym3Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "for col in ['id.orig_h', 'id.resp_h', 'proto', 'label']:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "X = MinMaxScaler().fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train = np.nan_to_num(X_train)\n",
        "X_test = np.nan_to_num(X_test)\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_balanced, y_balanced = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "desired_size = 521460\n",
        "indices = np.random.choice(X_balanced.shape[0], size=desired_size, replace=False)\n",
        "X_balanced_r = X_balanced[indices]\n",
        "y_balanced_r = y_balanced[indices]"
      ],
      "metadata": {
        "id": "1uu8t2NxnicK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from art.attacks.inference.membership_inference import MembershipInferenceBlackBoxRuleBased\n",
        "from art.estimators.classification import TensorFlowV2Classifier\n",
        "\n",
        "def build_model(input_dim, num_classes):\n",
        "    model = Sequential([\n",
        "        Dense(128, input_dim=input_dim, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def run_attack(classifier, X_train, X_test, y_train, y_test):\n",
        "    attack = MembershipInferenceBlackBoxRuleBased(classifier)\n",
        "    inferred_train = attack.infer(X_train, y_train)\n",
        "    inferred_test = attack.infer(X_test, y_test)\n",
        "    train_acc = np.sum(inferred_train) / len(inferred_train)\n",
        "    test_acc = 1 - (np.sum(inferred_test) / len(inferred_test))\n",
        "    acc = (train_acc * len(inferred_train) + test_acc * len(inferred_test)) / (len(inferred_train) + len(inferred_test))\n",
        "\n",
        "    true_labels = np.concatenate((np.ones(len(inferred_train)), np.zeros(len(inferred_test))))\n",
        "    predicted = np.concatenate((inferred_train, inferred_test))\n",
        "    precision = np.sum((predicted == 1) & (true_labels == 1)) / np.sum(predicted == 1) if np.sum(predicted == 1) else 1\n",
        "    recall = np.sum((predicted == 1) & (true_labels == 1)) / np.sum(true_labels == 1) if np.sum(true_labels == 1) else 1\n",
        "\n",
        "    return train_acc, test_acc, acc, precision, recall"
      ],
      "metadata": {
        "id": "h83S7DJZnmtV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_privacy as tfp\n",
        "results = []\n",
        "\n",
        "l2_norm_clip_values = [1.3, 1.5]\n",
        "noise_multipliers = [0.7, 0.8, 1.0, 1.2, 1.4, 2.7, 3.0]\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "delta = 1e-5\n",
        "n_samples = len(X_balanced_r)\n",
        "\n",
        "for l2_clip in l2_norm_clip_values:\n",
        "    for noise in noise_multipliers:\n",
        "        opt = tfp.privacy.optimizers.dp_optimizer_keras.DPKerasAdamOptimizer(\n",
        "            l2_norm_clip=l2_clip,\n",
        "            noise_multiplier=noise,\n",
        "            num_microbatches=1,\n",
        "        )\n",
        "\n",
        "        epsilon, _ = tfp.privacy.analysis.compute_dp_sgd_privacy_lib.compute_dp_sgd_privacy(\n",
        "            n=n_samples, batch_size=batch_size, noise_multiplier=noise, epochs=epochs, delta=delta\n",
        "        )\n",
        "\n",
        "        model = build_model(X.shape[1], len(np.unique(y)))\n",
        "        model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.fit(X_balanced_r, y_balanced_r, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        art_classifier = TensorFlowV2Classifier(\n",
        "            model=model,\n",
        "            loss_object=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "            optimizer=tf.keras.optimizers.Adam(),\n",
        "            nb_classes=5,\n",
        "            input_shape=(X.shape[1],),\n",
        "            clip_values=(0, 1),\n",
        "        )\n",
        "\n",
        "        y_pred = art_classifier.predict(X_test)\n",
        "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "        report = classification_report(y_test, y_pred_classes, output_dict=True)\n",
        "        acc_model = report['accuracy']\n",
        "\n",
        "        train_acc, test_acc, attack_acc, precision, recall = run_attack(art_classifier, X_train, X_test, y_train, y_test)\n",
        "\n",
        "        results.append({\n",
        "            'epsilon': round(epsilon, 4),\n",
        "            'noise': noise,\n",
        "            'l2_norm_clip': l2_clip,\n",
        "            'model_acc': acc_model,\n",
        "            'attack_acc': round(attack_acc, 4),\n",
        "            'attack_train_acc': round(train_acc, 4),\n",
        "            'attack_test_acc': round(test_acc, 4),\n",
        "            'attack_precision': round(precision, 4),\n",
        "            'attack_recall': round(recall, 4),\n",
        "        })"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rmsSZdCCoC1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = build_model(X.shape[1], len(np.unique(y)))\n",
        "baseline_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "baseline_model.fit(X_balanced_r, y_balanced_r, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "baseline_classifier = TensorFlowV2Classifier(\n",
        "    model=baseline_model,\n",
        "    loss_object=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    nb_classes=5,\n",
        "    input_shape=(X.shape[1],),\n",
        "    clip_values=(0, 1),\n",
        ")\n",
        "\n",
        "y_pred_base = baseline_classifier.predict(X_test)\n",
        "y_pred_base_classes = np.argmax(y_pred_base, axis=1)\n",
        "report_base = classification_report(y_test, y_pred_base_classes, output_dict=True)\n",
        "acc_baseline = report_base['accuracy']\n",
        "\n",
        "train_acc, test_acc, attack_acc, precision, recall = run_attack(baseline_classifier, X_train, X_test, y_train, y_test)\n",
        "\n",
        "results.append({\n",
        "    'epsilon': 'baseline',\n",
        "    'noise': 0,\n",
        "    'l2_norm_clip': 0,\n",
        "    'model_acc': acc_baseline,\n",
        "    'attack_acc': round(attack_acc, 4),\n",
        "    'attack_train_acc': round(train_acc, 4),\n",
        "    'attack_test_acc': round(test_acc, 4),\n",
        "    'attack_precision': round(precision, 4),\n",
        "    'attack_recall': round(recall, 4),\n",
        "})"
      ],
      "metadata": {
        "id": "gWlOHj2hoR0s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar linhas com epsilon numérico\n",
        "private_df = results_df[results_df['epsilon'] != 'baseline'].copy()\n",
        "private_df['epsilon'] = private_df['epsilon'].astype(float)\n",
        "private_df = private_df.sort_values(by='epsilon')\n",
        "\n",
        "# Separar baseline\n",
        "baseline_df = results_df[results_df['epsilon'] == 'baseline']\n",
        "\n",
        "# Concatenar com baseline no final (ou no início, se quiser)\n",
        "final_df = pd.concat([private_df, baseline_df], ignore_index=True)\n",
        "\n",
        "display(final_df)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QuuBhGhGopE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}